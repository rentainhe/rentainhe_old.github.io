<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="本文主要介绍了detectron2中的DenseDetector类">
<meta property="og:type" content="article">
<meta property="og:title" content="Detectron2 Learning Notes(6): DenseDetector">
<meta property="og:url" content="http://example.com/2022/05/26/detectron2-retinanet-loss/index.html">
<meta property="og:site_name" content="RenTianhe&#39;s Blog">
<meta property="og:description" content="本文主要介绍了detectron2中的DenseDetector类">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-05-26T05:51:14.000Z">
<meta property="article:modified_time" content="2022-06-17T14:55:20.410Z">
<meta property="article:author" content="Ren Tianhe">
<meta property="article:tag" content="Detectron2">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2022/05/26/detectron2-retinanet-loss/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Detectron2 Learning Notes(6): DenseDetector | RenTianhe's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">RenTianhe's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">A man is only as good as what he loves.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">14</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">14</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">64</span></a>

  </li>
        <li class="menu-item menu-item-projects">

    <a href="/projects/" rel="section"><i class="fab fa-github fa-fw"></i>projects</a>

  </li>
        <li class="menu-item menu-item-publications">

    <a href="/publications/" rel="section"><i class="fa fa-book fa-fw"></i>publications</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/05/26/detectron2-retinanet-loss/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ren Tianhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RenTianhe's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Detectron2 Learning Notes(6): DenseDetector
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-05-26 13:51:14" itemprop="dateCreated datePublished" datetime="2022-05-26T13:51:14+08:00">2022-05-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-06-17 22:55:20" itemprop="dateModified" datetime="2022-06-17T22:55:20+08:00">2022-06-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Detectron2/" itemprop="url" rel="index"><span itemprop="name">Detectron2</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>23k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>21 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>本文主要介绍了detectron2中的DenseDetector类</p>
<span id="more"></span>
<h2 id="Contents-2">Contents</h2>
<ul>
<li><a href="#contents">Contents</a></li>
<li><a href="#densedetector">DenseDetector</a>
<ul>
<li><a href="#forward">Forward</a>
<ul>
<li><a href="#input">input</a></li>
<li><a href="#preprocess_image">preprocess_image</a></li>
<li><a href="#backbone">backbone</a></li>
<li><a href="#predictions">predictions</a></li>
<li><a href="#forward_training">forward_training</a></li>
<li><a href="#retinanet-loss-compute">RetinaNet Loss Compute</a></li>
</ul>
</li>
<li><a href="#inference">Inference</a>
<ul>
<li><a href="#_decode_single_level_predictions">_decode_single_level_predictions</a></li>
<li><a href="#box2boxtransform">Box2BoxTransform</a></li>
<li><a href="#_decode_multi_level_predictions">_decode_multi_level_predictions</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="DenseDetector">DenseDetector</h2>
<p><code>DenseDetector</code>是继承自<code>nn.Module</code>实现的<code>One-Stage</code>检测器的父类, Detectron2中的<code>One-Stage</code>算法基本都继承自<code>DenseDetector</code></p>
<h3 id="Forward">Forward</h3>
<p>Forward的整体流程流程如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, batched_inputs: <span class="type">List</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, Tensor]]</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        batched_inputs: a list, batched outputs of :class:`DatasetMapper` .</span></span><br><span class="line"><span class="string">            Each item in the list contains the inputs for one image.</span></span><br><span class="line"><span class="string">            For now, each item in the list is a dict that contains:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            * image: Tensor, image in (C, H, W) format.</span></span><br><span class="line"><span class="string">            * instances: Instances</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            Other information that&#x27;s included in the original dicts, such as:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            * &quot;height&quot;, &quot;width&quot; (int): the output resolution of the model, used in inference.</span></span><br><span class="line"><span class="string">                See :meth:`postprocess` for details.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        In training, dict[str, Tensor]: mapping from a named loss to a tensor storing the</span></span><br><span class="line"><span class="string">        loss. Used during training only. In inference, the standard output format, described</span></span><br><span class="line"><span class="string">        in :doc:`/tutorials/models`.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    images = self.preprocess_image(batched_inputs)</span><br><span class="line">    features = self.backbone(images.tensor)</span><br><span class="line">    features = [features[f] <span class="keyword">for</span> f <span class="keyword">in</span> self.head_in_features]</span><br><span class="line">    predictions = self.head(features)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.training:</span><br><span class="line">        <span class="keyword">assert</span> <span class="keyword">not</span> torch.jit.is_scripting(), <span class="string">&quot;Not supported&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="string">&quot;instances&quot;</span> <span class="keyword">in</span> batched_inputs[<span class="number">0</span>], <span class="string">&quot;Instance annotations are missing in training!&quot;</span></span><br><span class="line">        gt_instances = [x[<span class="string">&quot;instances&quot;</span>].to(self.device) <span class="keyword">for</span> x <span class="keyword">in</span> batched_inputs]</span><br><span class="line">        <span class="keyword">return</span> self.forward_training(images, features, predictions, gt_instances)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        results = self.forward_inference(images, features, predictions)</span><br><span class="line">        <span class="keyword">if</span> torch.jit.is_scripting():</span><br><span class="line">            <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">        processed_results = []</span><br><span class="line">        <span class="keyword">for</span> results_per_image, input_per_image, image_size <span class="keyword">in</span> <span class="built_in">zip</span>(</span><br><span class="line">            results, batched_inputs, images.image_sizes</span><br><span class="line">        ):</span><br><span class="line">            height = input_per_image.get(<span class="string">&quot;height&quot;</span>, image_size[<span class="number">0</span>])</span><br><span class="line">            width = input_per_image.get(<span class="string">&quot;width&quot;</span>, image_size[<span class="number">1</span>])</span><br><span class="line">            r = detector_postprocess(results_per_image, height, width)</span><br><span class="line">            processed_results.append(&#123;<span class="string">&quot;instances&quot;</span>: r&#125;)</span><br><span class="line">        <span class="keyword">return</span> processed_results</span><br></pre></td></tr></table></figure>
<h4 id="input">input</h4>
<ul>
<li><code>DenseDetector</code>的forward函数的输入是 <code>batched_inputs</code>, 是一个 <code>List[Dict]</code>, 其中主要包括了原始图片的一些信息, 以及这个图片上的ground_truth (Instances), 以<code>batch_size=2</code>为例子:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># batch_size = 2 的时候这个list的长度为2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(batched_inputs)</span><br><span class="line"><span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>batched_inputs[<span class="number">0</span>].keys()</span><br><span class="line">dict_keys([<span class="string">&#x27;file_name&#x27;</span>, <span class="string">&#x27;height&#x27;</span>, <span class="string">&#x27;width&#x27;</span>, <span class="string">&#x27;image_id&#x27;</span>, <span class="string">&#x27;image&#x27;</span>, <span class="string">&#x27;instances&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># file_name存储的是图片的路径</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>batched_inputs[<span class="number">0</span>][<span class="string">&quot;file_name&quot;</span>]</span><br><span class="line"><span class="string">&#x27;datasets/coco/train2017/000000481749.jpg&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># height &amp; width 是模型输出的大小, 即 output resolution of the model</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>batched_inputs[<span class="number">0</span>][<span class="string">&quot;height&quot;</span>]</span><br><span class="line"><span class="number">425</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>batched_inputs[<span class="number">0</span>][<span class="string">&quot;width&quot;</span>]</span><br><span class="line"><span class="number">640</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># image 是输入的大小 input resolution</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>batched_inputs[<span class="number">0</span>][<span class="string">&quot;image&quot;</span>].shape</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">768</span>, <span class="number">1157</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># instances 存储了 ground truth 的信息, 可以看到这个sample里有 2 个ground truth</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>batched_inputs[<span class="number">0</span>][<span class="string">&quot;instances&quot;</span>]</span><br><span class="line">Instances(num_instances=<span class="number">2</span>, image_height=<span class="number">768</span>, image_width=<span class="number">1157</span>, fields=[gt_boxes: Boxes(tensor([[<span class="number">442.9683</span>, <span class="number">232.9299</span>, <span class="number">589.5819</span>, <span class="number">440.9404</span>],</span><br><span class="line">        [<span class="number">399.1469</span>, <span class="number">220.4431</span>, <span class="number">459.1844</span>, <span class="number">240.6460</span>]])), gt_classes: tensor([<span class="number">16</span>, <span class="number">29</span>])])</span><br></pre></td></tr></table></figure>
<h4 id="preprocess-image">preprocess_image</h4>
<p>首先需要用<code>preprocess_image</code>函数来处理<code>batched_inputs</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess_image</span>(<span class="params">self, batched_inputs: <span class="type">List</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, Tensor]]</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Normalize, pad and batch the input images.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    images = [self._move_to_current_device(x[<span class="string">&quot;image&quot;</span>]) <span class="keyword">for</span> x <span class="keyword">in</span> batched_inputs]</span><br><span class="line">    images = [(x - self.pixel_mean) / self.pixel_std <span class="keyword">for</span> x <span class="keyword">in</span> images]</span><br><span class="line">    images = ImageList.from_tensors(images, self.backbone.size_divisibility)</span><br><span class="line">    <span class="keyword">return</span> images</span><br></pre></td></tr></table></figure>
<p><code>preprocess_image</code>调用了<code>Imagelist</code>的<code>from_tensors</code>方法, 我们接下来看一下这个方法中的整体流程, 这个方法的主要作用是: <code>holds a list of images (of possibly varying sizes) as a single tensor</code>, 主要的做法是<code>padding the images to the same size</code>, 并且会将<code>original sizes</code>存储在<code>image_sizes</code>这个变量里</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">from_tensors</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">    tensors: <span class="type">List</span>[torch.Tensor], size_divisibility: <span class="built_in">int</span> = <span class="number">0</span>, pad_value: <span class="built_in">float</span> = <span class="number">0.0</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>) -&gt; &quot;ImageList&quot;:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        tensors: a tuple or list of `torch.Tensor`, each of shape (Hi, Wi) or</span></span><br><span class="line"><span class="string">            (C_1, ..., C_K, Hi, Wi) where K &gt;= 1. The Tensors will be padded</span></span><br><span class="line"><span class="string">            to the same shape with `pad_value`.</span></span><br><span class="line"><span class="string">        size_divisibility (int): If `size_divisibility &gt; 0`, add padding to ensure</span></span><br><span class="line"><span class="string">            the common height and width is divisible by `size_divisibility`.</span></span><br><span class="line"><span class="string">            This depends on the model and many models need a divisibility of 32.</span></span><br><span class="line"><span class="string">        pad_value (float): value to pad</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        an `ImageList`.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(tensors) &gt; <span class="number">0</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(tensors, (<span class="built_in">tuple</span>, <span class="built_in">list</span>))</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> tensors:</span><br><span class="line">        <span class="comment"># 在这个部分会进行一个检查, 先检查传入的数据是不是tensor, 然后判断一下这一系列tensor, 除了H和W维度之外都一致, 这样在将H和W pad到一个size之后才可以作为一个tensor保存</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(t, torch.Tensor), <span class="built_in">type</span>(t)</span><br><span class="line">        <span class="keyword">assert</span> t.shape[:-<span class="number">2</span>] == tensors[<span class="number">0</span>].shape[:-<span class="number">2</span>], t.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存了原来图片的size: [(800, 1199), (768, 1105)]</span></span><br><span class="line">    image_sizes = [(im.shape[-<span class="number">2</span>], im.shape[-<span class="number">1</span>]) <span class="keyword">for</span> im <span class="keyword">in</span> tensors]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将原来图片的size转换为tensor类型, 也就是说list里的tuple变成一个tensor, 调用了shapes_to_tensor的方法</span></span><br><span class="line">    <span class="comment"># image_sizes_tensor: [tensor([ 800, 1199]), tensor([ 768, 1105])]</span></span><br><span class="line">    image_sizes_tensor = [shapes_to_tensor(x) <span class="keyword">for</span> x <span class="keyword">in</span> image_sizes]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 得到了这个batch里最大的tensor的H和W的值: tensor([800, 1199])</span></span><br><span class="line">    max_size = torch.stack(image_sizes_tensor).<span class="built_in">max</span>(<span class="number">0</span>).values</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这个参数是为了让 (H, W) 可以被一个固定大小的stride整除, 方便后面生成anchors各种操作, 一般降采样32倍, 这里的取值为 32, 转换后的 max_size 为 (800, 1216)</span></span><br><span class="line">    <span class="keyword">if</span> size_divisibility &gt; <span class="number">1</span>:</span><br><span class="line">        stride = size_divisibility</span><br><span class="line">        <span class="comment"># the last two dims are H,W, both subject to divisibility requirement</span></span><br><span class="line">        max_size = (max_size + (stride - <span class="number">1</span>)).div(stride, rounding_mode=<span class="string">&quot;floor&quot;</span>) * stride</span><br><span class="line"></span><br><span class="line">    <span class="comment"># handle weirdness of scripting and tracing ...</span></span><br><span class="line">    <span class="keyword">if</span> torch.jit.is_scripting():</span><br><span class="line">        max_size: <span class="type">List</span>[<span class="built_in">int</span>] = max_size.to(dtype=torch.long).tolist()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> torch.jit.is_tracing():</span><br><span class="line">            image_sizes = image_sizes_tensor</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(tensors) == <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># This seems slightly (2%) faster.</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> check whether it&#x27;s faster for multiple images as well</span></span><br><span class="line">        image_size = image_sizes[<span class="number">0</span>]</span><br><span class="line">        padding_size = [<span class="number">0</span>, max_size[-<span class="number">1</span>] - image_size[<span class="number">1</span>], <span class="number">0</span>, max_size[-<span class="number">2</span>] - image_size[<span class="number">0</span>]]</span><br><span class="line">        batched_imgs = F.pad(tensors[<span class="number">0</span>], padding_size, value=pad_value).unsqueeze_(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 这里的batch_shape为[2, 3, tensor(800), tensor(1216)]</span></span><br><span class="line">        <span class="comment"># max_size can be a tensor in tracing mode, therefore convert to list</span></span><br><span class="line">        batch_shape = [<span class="built_in">len</span>(tensors)] + <span class="built_in">list</span>(tensors[<span class="number">0</span>].shape[:-<span class="number">2</span>]) + <span class="built_in">list</span>(max_size)</span><br><span class="line">        device = (</span><br><span class="line">            <span class="literal">None</span> <span class="keyword">if</span> torch.jit.is_scripting() <span class="keyword">else</span> (<span class="string">&quot;cpu&quot;</span> <span class="keyword">if</span> torch.jit.is_tracing() <span class="keyword">else</span> <span class="literal">None</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 首先创建一个全为pad_value的tensor, 调用tensor.new_full方法, pad_value手动指定, 默认为0</span></span><br><span class="line">        batched_imgs = tensors[<span class="number">0</span>].new_full(batch_shape, pad_value, device=device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 进行padding操作, 这里使用了copy的方法, 应该是向右和向下pad</span></span><br><span class="line">        batched_imgs = move_device_like(batched_imgs, tensors[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">for</span> img, pad_img <span class="keyword">in</span> <span class="built_in">zip</span>(tensors, batched_imgs):</span><br><span class="line">            pad_img[..., : img.shape[-<span class="number">2</span>], : img.shape[-<span class="number">1</span>]].copy_(img)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ImageList(batched_imgs.contiguous(), image_sizes)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># batched_imgs: 组织成一个batch的tensor, 其中每个元素都pad到了max_size</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>batched_imgs.shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">800</span>, <span class="number">1216</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># image_sizes: 包含原始图片size的一个list</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>image_sizes</span><br><span class="line">[(<span class="number">800</span>, <span class="number">1199</span>), (<span class="number">768</span>, <span class="number">1105</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以通过以下两种调用方式得到数据</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ImageList.tensor</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ImageList.image_sizes</span><br></pre></td></tr></table></figure>
<h4 id="backbone">backbone</h4>
<p>在处理完输入数据之后, 可以通过backbone得到backbone输入的特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">images = self.preprocess_image(batched_inputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此时返回的features是一个dict类型</span></span><br><span class="line"><span class="comment"># features.keys(): dict_keys([&#x27;p3&#x27;, &#x27;p4&#x27;, &#x27;p5&#x27;, &#x27;p6&#x27;, &#x27;p7&#x27;])</span></span><br><span class="line">features = self.backbone(images.tensor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># self.head_in_features = [&#x27;p3&#x27;, &#x27;p4&#x27;, &#x27;p5&#x27;, &#x27;p6&#x27;, &#x27;p7&#x27;]</span></span><br><span class="line">features = [features[f] <span class="keyword">for</span> f <span class="keyword">in</span> self.head_in_features]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此时会得到FPN输出的特征</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>features[<span class="number">0</span>].shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">256</span>, <span class="number">96</span>, <span class="number">140</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>features[<span class="number">1</span>].shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">256</span>, <span class="number">48</span>, <span class="number">70</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>features[<span class="number">2</span>].shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">256</span>, <span class="number">24</span>, <span class="number">35</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>features[<span class="number">3</span>].shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">256</span>, <span class="number">12</span>, <span class="number">18</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>features[<span class="number">4</span>].shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">256</span>, <span class="number">6</span>, <span class="number">9</span>])</span><br></pre></td></tr></table></figure>
<h4 id="predictions">predictions</h4>
<p>在得到了FPN的特征输出之后, 会将这个特征组织成一个list输入到head中, 得到predictions</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">features = [features[f] <span class="keyword">for</span> f <span class="keyword">in</span> self.head_in_features]</span><br><span class="line">predictions = self.head(features)</span><br></pre></td></tr></table></figure>
<p>这里我们以RetinaNet为例, 看看RetinaNet的head的输出:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">self.cls_score = nn.Conv2d(</span><br><span class="line">    conv_dims[-<span class="number">1</span>], num_anchors * num_classes, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span></span><br><span class="line">)</span><br><span class="line">self.bbox_pred = nn.Conv2d(</span><br><span class="line">    conv_dims[-<span class="number">1</span>], num_anchors * <span class="number">4</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, features: <span class="type">List</span>[Tensor]</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        features (list[Tensor]): FPN feature map tensors in high to low resolution.</span></span><br><span class="line"><span class="string">            Each tensor in the list correspond to different feature levels.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        logits (list[Tensor]): #lvl tensors, each has shape (N, AxK, Hi, Wi).</span></span><br><span class="line"><span class="string">            The tensor predicts the classification probability</span></span><br><span class="line"><span class="string">            at each spatial position for each of the A anchors and K object</span></span><br><span class="line"><span class="string">            classes.</span></span><br><span class="line"><span class="string">        bbox_reg (list[Tensor]): #lvl tensors, each has shape (N, Ax4, Hi, Wi).</span></span><br><span class="line"><span class="string">            The tensor predicts 4-vector (dx,dy,dw,dh) box</span></span><br><span class="line"><span class="string">            regression values for every anchor. These values are the</span></span><br><span class="line"><span class="string">            relative offset between the anchor and the ground truth box.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(features) == self._num_features</span><br><span class="line">    logits = []</span><br><span class="line">    bbox_reg = []</span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> features:</span><br><span class="line">        logits.append(self.cls_score(self.cls_subnet(feature)))</span><br><span class="line">        bbox_reg.append(self.bbox_pred(self.bbox_subnet(feature)))</span><br><span class="line">    <span class="keyword">return</span> logits, bbox_reg</span><br></pre></td></tr></table></figure>
<p>每层特征都经过了<code>cls_score</code>和<code>bbox_pred</code>这两个分支, 用于预测分类的logits以及回归框, 输出的channel维度分别为<code>num_anchors * num_classes</code>以及<code>num_anchors * 4</code>, 最后返回两个<code>list</code>, 分别是不同<code>level</code>特征的预测, <code>bbox_reg</code>的长度为5</p>
<h4 id="forward-training">forward_training</h4>
<p>最后调用<code>forward_training</code>函数, 这个函数是根据不同的网络进行重写, 输入的参数为:</p>
<ul>
<li><code>images</code>: ImageLists类, 通过<code>images.tensor</code>和<code>images.image_sizes</code>得到经过pad后输入的tensor以及原图size</li>
<li><code>features</code>: FPN输出的特征, 是一个list, 每个list里都是FPN每个level的特征输出</li>
<li><code>predictions</code>: head预测的输出, 由两个长度和FPN输出的features数量相同的list组成, 分别代表<code>logits</code>和<code>bbox_reg</code></li>
<li><code>gt_instances</code>: ground truth</li>
</ul>
<p>这里用RetinaNet的forward_training进行举例:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_training</span>(<span class="params">self, images, features, predictions, gt_instances</span>):</span></span><br><span class="line">    <span class="comment"># Transpose the Hi*Wi*A dimension to the middle:</span></span><br><span class="line">    <span class="comment"># 得到模型的输出</span></span><br><span class="line">    pred_logits, pred_anchor_deltas = self._transpose_dense_predictions(</span><br><span class="line">        predictions, [self.num_classes, <span class="number">4</span>]</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 得到候选anchors</span></span><br><span class="line">    anchors = self.anchor_generator(features)</span><br><span class="line">    <span class="comment"># 对anchors分配标签</span></span><br><span class="line">    gt_labels, gt_boxes = self.label_anchors(anchors, gt_instances)</span><br><span class="line">    <span class="comment"># 计算loss</span></span><br><span class="line">    <span class="keyword">return</span> self.losses(anchors, pred_logits, gt_labels, pred_anchor_deltas, gt_boxes)</span><br></pre></td></tr></table></figure>
<p>首先进行transpose_dense_predictions操作:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">permute_to_N_HWA_K</span>(<span class="params">tensor, K: <span class="built_in">int</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Transpose/reshape a tensor from (N, (Ai x K), H, W) to (N, (HxWxAi), K)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> tensor.dim() == <span class="number">4</span>, tensor.shape</span><br><span class="line">    N, _, H, W = tensor.shape</span><br><span class="line">    tensor = tensor.view(N, -<span class="number">1</span>, K, H, W)</span><br><span class="line">    tensor = tensor.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    tensor = tensor.reshape(N, -<span class="number">1</span>, K)  <span class="comment"># Size=(N,HWA,K)</span></span><br><span class="line">    <span class="keyword">return</span> tensor</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_transpose_dense_predictions</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">    self, predictions: <span class="type">List</span>[<span class="type">List</span>[Tensor]], dims_per_anchor: <span class="type">List</span>[<span class="built_in">int</span>]</span></span></span><br><span class="line"><span class="params"><span class="function"></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[Tensor]]:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Transpose the dense per-level predictions.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        predictions: a list of outputs, each is a list of per-level</span></span><br><span class="line"><span class="string">            predictions with shape (N, Ai x K, Hi, Wi), where N is the</span></span><br><span class="line"><span class="string">            number of images, Ai is the number of anchors per location on</span></span><br><span class="line"><span class="string">            level i, K is the dimension of predictions per anchor.</span></span><br><span class="line"><span class="string">        dims_per_anchor: the value of K for each predictions. e.g. 4 for</span></span><br><span class="line"><span class="string">            box prediction, #classes for classification prediction.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        List[List[Tensor]]: each prediction is transposed to (N, Hi x Wi x Ai, K).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(predictions) == <span class="built_in">len</span>(dims_per_anchor)</span><br><span class="line">    res: <span class="type">List</span>[<span class="type">List</span>[Tensor]] = []</span><br><span class="line">    <span class="comment"># predictions: [list, list]</span></span><br><span class="line">    <span class="comment"># dims_per_anchor: [80, 4]</span></span><br><span class="line">    <span class="keyword">for</span> pred, dim_per_anchor <span class="keyword">in</span> <span class="built_in">zip</span>(predictions, dims_per_anchor):</span><br><span class="line">        pred = [permute_to_N_HWA_K(x, dim_per_anchor) <span class="keyword">for</span> x <span class="keyword">in</span> pred]</span><br><span class="line">        res.append(pred)</span><br><span class="line">    <span class="comment"># res应该也是返回包含batch个tensor的list, 其中每个list都是每个样本的预测输出,</span></span><br><span class="line">    <span class="comment"># res: [tensor, tensor], tensor size: (N, H x W x A, K), N是images数量, HWA表示总的anchors数量</span></span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p><code>_transpose_dense_predictions</code>的输入是一个<code>List[List[Tensor]]]</code>, 其中这个List的长度为2, 这里的2表示, 一组是prediction cls的结果, 一个是prediction bbox_reg的结果, 也就是FPN返回的结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(predictions)  <span class="comment"># predict_cls 和 bbox_reg 的结果</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(predictions[<span class="number">0</span>])  <span class="comment"># FPN五层的输出</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(predictions[<span class="number">0</span>][<span class="number">0</span>].shape)</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">720</span>, <span class="number">96</span>, <span class="number">148</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(predictions[<span class="number">1</span>][<span class="number">0</span>].shape)</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">36</span>, <span class="number">96</span>, <span class="number">148</span>])</span><br></pre></td></tr></table></figure>
<p>经过transpose操作后返回的结果作为<code>pred_logits</code>和<code>pred_anchor_deltas</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_training</span>(<span class="params">self, images, features, predictions, gt_instances</span>):</span></span><br><span class="line">    <span class="comment"># Transpose the Hi*Wi*A dimension to the middle:</span></span><br><span class="line">    <span class="comment"># 得到模型的输出</span></span><br><span class="line">    pred_logits, pred_anchor_deltas = self._transpose_dense_predictions(</span><br><span class="line">        predictions, [self.num_classes, <span class="number">4</span>]</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>然后list中的每个元素大小都为<code>(B, num_anchors, 4)</code>, <code>num_anchors</code>是FPN每层feature的预测, <code>logits</code>也是FPN每层Feature预测的结果, 也是一个list, 长度为5(FPN有五层特征), list中每个元素大小为<code>(B, num_anchors, 80)</code>, 表示预测的类别</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(pred_logits)</span><br><span class="line"><span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pred_logits[<span class="number">0</span>].shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">136800</span>, <span class="number">80</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pred_logits[<span class="number">1</span>].shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">34200</span>, <span class="number">80</span>])  <span class="comment"># 少4倍, 很合理, h和w都少了一半</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(bbox_reg)</span><br><span class="line"><span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pred_anchor_deltas[<span class="number">0</span>].shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">136800</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pred_anchor_deltas[<span class="number">1</span>].shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">34200</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure>
<h4 id="RetinaNet-Loss-Compute">RetinaNet Loss Compute</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">losses</span>(<span class="params">self, anchors, pred_logits, gt_labels, pred_anchor_deltas, gt_boxes</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        anchors (list[Boxes]): a list of #feature level Boxes</span></span><br><span class="line"><span class="string">        gt_labels, gt_boxes: see output of :meth:`RetinaNet.label_anchors`.</span></span><br><span class="line"><span class="string">            Their shapes are (N, R) and (N, R, 4), respectively, where R is</span></span><br><span class="line"><span class="string">            the total number of anchors across levels, i.e. sum(Hi x Wi x Ai)</span></span><br><span class="line"><span class="string">        pred_logits, pred_anchor_deltas: both are list[Tensor]. Each element in the</span></span><br><span class="line"><span class="string">            list corresponds to one level and has shape (N, Hi * Wi * Ai, K or 4).</span></span><br><span class="line"><span class="string">            Where K is the number of classes used in `pred_logits`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        dict[str, Tensor]:</span></span><br><span class="line"><span class="string">            mapping from a named loss to a scalar tensor storing the loss.</span></span><br><span class="line"><span class="string">            Used during training only. The dict keys are: &quot;loss_cls&quot; and &quot;loss_box_reg&quot;</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num_images = <span class="built_in">len</span>(gt_labels)</span><br><span class="line">    <span class="comment"># 假设 image nums 为 2</span></span><br><span class="line">    <span class="comment"># 输入的 gt_labels 是一个list, list[tensor, tensor], tensor size: (1, anchor_nums)</span></span><br><span class="line">    <span class="comment"># 这里进行了stack的操作, gt_labels得到的size大小为(num_images, anchor_nums)</span></span><br><span class="line">    <span class="comment"># gt_labels.shape == (2, 163206)</span></span><br><span class="line">    gt_labels = torch.stack(gt_labels)  <span class="comment"># (N, R)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># valid_mask表示有效的anchor</span></span><br><span class="line">    valid_mask = gt_labels &gt;= <span class="number">0</span></span><br><span class="line">    <span class="comment"># pos_mask表示被分配到ground truth label的正样本, 而不是 label == self.num_classes的背景样</span></span><br><span class="line">    pos_mask = (gt_labels &gt;= <span class="number">0</span>) &amp; (gt_labels != self.num_classes)</span><br><span class="line">    <span class="comment"># 总的正样本的数量</span></span><br><span class="line">    num_pos_anchors = pos_mask.<span class="built_in">sum</span>().item()</span><br><span class="line">    get_event_storage().put_scalar(<span class="string">&quot;num_pos_anchors&quot;</span>, num_pos_anchors / num_images)</span><br><span class="line">    normalizer = self._ema_update(<span class="string">&quot;loss_normalizer&quot;</span>, <span class="built_in">max</span>(num_pos_anchors, <span class="number">1</span>), <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># classification and regression loss</span></span><br><span class="line">    <span class="comment"># gt_labels.shape == (2, 163206)</span></span><br><span class="line">    <span class="comment"># gt_labels[valid_mask] = (325591,), 取所有为True的位置的值</span></span><br><span class="line">    <span class="comment"># gt_labels[valid_mask]表示的是有效的anchor, 而非ignored的anchor</span></span><br><span class="line">    <span class="comment"># 传入F.one_hot向量时num_classes需要+1, 是因为需要考虑背景类</span></span><br><span class="line">    <span class="comment"># 至于最后取[:, :-1]操作意味着, 如果一个anchor是背景类的话</span></span><br><span class="line">    <span class="comment"># 那这个anchor对应的label则为[0, 0, ..., 1], 取[:, :-1]的话则为[0, 0, ..., 0], 在计算Loss的时候就不考虑进去</span></span><br><span class="line">    gt_labels_target = F.one_hot(gt_labels[valid_mask], num_classes=self.num_classes + <span class="number">1</span>)[</span><br><span class="line">        :, :-<span class="number">1</span></span><br><span class="line">    ]  <span class="comment"># no loss for the last (background) class</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算分类Loss</span></span><br><span class="line">    <span class="comment"># cat(pred_logits, dim=1).shape == (2, 163206, 80)</span></span><br><span class="line">    <span class="comment"># valid_mask.shape == (2, 163206)</span></span><br><span class="line">    <span class="comment"># cat(pred_logits, dim=1)[valid_mask].shape == (valid_mask_nums, 80)</span></span><br><span class="line">    <span class="comment"># gt_labels_targets.shape == (valid_mask_nums, 80) 并且是一个one_hot向量</span></span><br><span class="line">    loss_cls = sigmoid_focal_loss_jit(</span><br><span class="line">        cat(pred_logits, dim=<span class="number">1</span>)[valid_mask],</span><br><span class="line">        gt_labels_target.to(pred_logits[<span class="number">0</span>].dtype),</span><br><span class="line">        alpha=self.focal_loss_alpha,</span><br><span class="line">        gamma=self.focal_loss_gamma,</span><br><span class="line">        reduction=<span class="string">&quot;sum&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算回归loss</span></span><br><span class="line">    loss_box_reg = _dense_box_regression_loss(</span><br><span class="line">        anchors,</span><br><span class="line">        self.box2box_transform,</span><br><span class="line">        pred_anchor_deltas,</span><br><span class="line">        gt_boxes,</span><br><span class="line">        pos_mask,</span><br><span class="line">        box_reg_loss_type=self.box_reg_loss_type,</span><br><span class="line">        smooth_l1_beta=self.smooth_l1_beta,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;loss_cls&quot;</span>: loss_cls / normalizer,</span><br><span class="line">        <span class="string">&quot;loss_box_reg&quot;</span>: loss_box_reg / normalizer,</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h3 id="Inference">Inference</h3>
<p>接下来介绍DenseDetector的Inference部分, 有几个和test相关的参数</p>
<ul>
<li><code>test_score_thresh=0.05</code>: inference cls score, 只有分类置信度大于这个score的anchors才会参与inference</li>
<li><code>test_topk_candidates=1000</code>: Select topk candidates before NMS, 选择topk=1000预测的Anchors参与NMS的计算</li>
<li><code>test_nms_thresh=0.5</code>: overlap threshold used for non-maximum suppression</li>
<li><code>max_detections_per_image=100</code>: 每张图最多检测出来的物体数量, 不超过100对于coco</li>
</ul>
<p>首先我们看一下<code>forward_inference</code>的输入:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_inference</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">    self, images: ImageList, features: <span class="type">List</span>[Tensor], predictions: <span class="type">List</span>[<span class="type">List</span>[Tensor]]</span></span></span><br><span class="line"><span class="params"><span class="function"></span>):</span></span><br></pre></td></tr></table></figure>
<p><code>forward_inference</code>的输入总共有三个:</p>
<ul>
<li><code>images</code>: 包括输入图片的信息, <code>images.image_sizes</code>, <code>images.tensor</code>等</li>
<li><code>features</code>: <code>FPN</code>的不同level的特征输出:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(features)</span><br><span class="line"><span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>features[<span class="number">0</span>].shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">256</span>, <span class="number">100</span>, <span class="number">152</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>features[<span class="number">1</span>].shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">256</span>, <span class="number">50</span>, <span class="number">76</span>])</span><br></pre></td></tr></table></figure>
<ul>
<li><code>predictions</code>: 模型预测的<code>bbox_reg</code>以及<code>cls</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(predictions[<span class="number">0</span>])</span><br><span class="line"><span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>predictions[<span class="number">0</span>][<span class="number">0</span>].shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">720</span>, <span class="number">100</span>, <span class="number">152</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>predictions[<span class="number">1</span>][<span class="number">0</span>].shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">36</span>, <span class="number">100</span>, <span class="number">152</span>])</span><br></pre></td></tr></table></figure>
<p>然后会对输入的features和images进行预处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">pred_logits, pred_anchor_deltas = self._transpose_dense_predictions(</span><br><span class="line">    predictions, [self.num_classes, <span class="number">4</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pred_logits[<span class="number">0</span>].shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">136800</span>, <span class="number">80</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pred_logits[<span class="number">1</span>].shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">34200</span>, <span class="number">80</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pred_anchor_deltas[<span class="number">0</span>].shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">136800</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pred_anchor_deltas[<span class="number">1</span>].shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">34200</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure>
<p>然后首先会对输出的cls scores进行sigmoid操作, 然后重新整合一下pred_anchor_deltas</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">results: <span class="type">List</span>[Instances] = []</span><br><span class="line"><span class="keyword">for</span> img_idx, image_size <span class="keyword">in</span> <span class="built_in">enumerate</span>(images.image_sizes):</span><br><span class="line">    <span class="comment"># 长度为5的list, (anchors_nums, 80) &amp; (anchor_nums, 4)</span></span><br><span class="line">    scores_per_image = [x[img_idx].sigmoid_() <span class="keyword">for</span> x <span class="keyword">in</span> pred_logits]</span><br><span class="line">    deltas_per_image = [x[img_idx] <span class="keyword">for</span> x <span class="keyword">in</span> pred_anchor_deltas]</span><br><span class="line">    <span class="comment"># 核心的推理代码</span></span><br><span class="line">    results_per_image = self.inference_single_image(</span><br><span class="line">        anchors, scores_per_image, deltas_per_image, image_size</span><br><span class="line">    )</span><br><span class="line">    results.append(results_per_image)</span><br><span class="line"><span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<h4 id="decode-single-level-predictions">_decode_single_level_predictions</h4>
<p>Decode boxes and classification predictions of one featuer level, by the following steps:</p>
<ol>
<li>filter the predictions based on score threshold and top K scores.</li>
<li>transform the box regression outputs</li>
<li>return the predicted scores, classes and boxes</li>
</ol>
<p>需要传入以下几个参数</p>
<ul>
<li>anchors: 这层feature的anchors, <code>anchors.tensor.shape: (anchor_nums, 4)</code></li>
<li>pred_scores: 预测出来的每个anchor的cls score, <code>shape: (anchor_nums, 80)</code></li>
<li>pred_deltas: 预测出来每个anchor的偏移值, <code>shape: (anchor_nums, 4)</code></li>
<li>topk_candidates: 只选择cls score topk的anchor</li>
<li>image_size: <code>(H, W)</code></li>
</ul>
<p>整体流程解析</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 只保留置信度大于score_thresh的anchor</span></span><br><span class="line">keep_idxs = pred_scores &gt; score_thresh</span><br><span class="line">pred_scores = pred_scores[keep_idxs]</span><br><span class="line">topk_idxs = torch.nonzero(keep_idxs)  <span class="comment"># Kx2</span></span><br><span class="line"><span class="comment"># keep_idxs中为True的位置表示保留的anchor, 使用torch.nonzero得到的是True的位置</span></span><br><span class="line"><span class="comment"># 其中dim=0表示数量, 是一个Kx2大小的tensor</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Keep top k top scoring boxes only</span></span><br><span class="line">num_topk = <span class="built_in">min</span>(topk_candidates, topk_idxs.size(<span class="number">0</span>))</span><br><span class="line">pred_scores, idxs = pred_scores.topk(num_topk)</span><br><span class="line">topk_idxs = topk_idxs[idxs]</span><br><span class="line"></span><br><span class="line">anchor_idxs, classes_idxs = topk_idxs.unbind(dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>用一段代码举例:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">pred_scores = torch.rand(<span class="number">100</span>, <span class="number">80</span>)</span><br><span class="line">score_thresh = <span class="number">0.05</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Keep boxes with confidence score higher than threshold</span></span><br><span class="line">keep_idxs = pred_scores &gt; score_thresh</span><br><span class="line"><span class="built_in">print</span>(keep_idxs)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tensor([[ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  ...,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>],</span><br><span class="line">            [ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  ...,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>],</span><br><span class="line">            [ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  ...,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>],</span><br><span class="line">            ...,</span><br><span class="line">            [ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  ...,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>],</span><br><span class="line">            [<span class="literal">False</span>,  <span class="literal">True</span>, <span class="literal">False</span>,  ...,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>],</span><br><span class="line">            [ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  ...,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>]])</span><br><span class="line"></span><br><span class="line">pred_scores = pred_scores[keep_idxs]</span><br><span class="line"><span class="built_in">print</span>(pred_scores)  <span class="comment"># size: (keep_nums, ), e.g., (7610, )</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tensor([<span class="number">0.3582</span>, <span class="number">0.9010</span>, <span class="number">0.1929</span>,  ..., <span class="number">0.1129</span>, <span class="number">0.8842</span>, <span class="number">0.7203</span>])</span><br><span class="line"></span><br><span class="line">topk_idxs = torch.nonzero(keep_idxs)  <span class="comment"># Kx2</span></span><br><span class="line"><span class="built_in">print</span>(topk_idxs.shape)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.Size([<span class="number">7562</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(topk_idxs)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tensor([[ <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">            [ <span class="number">0</span>,  <span class="number">2</span>],</span><br><span class="line">            [ <span class="number">0</span>,  <span class="number">3</span>],</span><br><span class="line">            ...,</span><br><span class="line">            [<span class="number">99</span>, <span class="number">77</span>],</span><br><span class="line">            [<span class="number">99</span>, <span class="number">78</span>],</span><br><span class="line">            [<span class="number">99</span>, <span class="number">79</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Keep top k top scoring boxes only</span></span><br><span class="line">num_topk = <span class="built_in">min</span>(<span class="number">50</span>, topk_idxs.size(<span class="number">0</span>))</span><br><span class="line">pred_scores, idxs = pred_scores.topk(num_topk)</span><br><span class="line"><span class="built_in">print</span>(pred_scores)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tensor([<span class="number">0.9999</span>, <span class="number">0.9996</span>, <span class="number">0.9994</span>, <span class="number">0.9994</span>, <span class="number">0.9992</span>, <span class="number">0.9989</span>, <span class="number">0.9988</span>, <span class="number">0.9987</span>, <span class="number">0.9985</span>,</span><br><span class="line">            <span class="number">0.9983</span>, <span class="number">0.9983</span>, <span class="number">0.9983</span>, <span class="number">0.9982</span>, <span class="number">0.9982</span>, <span class="number">0.9982</span>, <span class="number">0.9976</span>, <span class="number">0.9974</span>, <span class="number">0.9974</span>,</span><br><span class="line">            <span class="number">0.9973</span>, <span class="number">0.9971</span>, <span class="number">0.9970</span>, <span class="number">0.9968</span>, <span class="number">0.9967</span>, <span class="number">0.9964</span>, <span class="number">0.9963</span>, <span class="number">0.9962</span>, <span class="number">0.9962</span>,</span><br><span class="line">            <span class="number">0.9962</span>, <span class="number">0.9960</span>, <span class="number">0.9958</span>, <span class="number">0.9958</span>, <span class="number">0.9957</span>, <span class="number">0.9957</span>, <span class="number">0.9956</span>, <span class="number">0.9956</span>, <span class="number">0.9955</span>,</span><br><span class="line">            <span class="number">0.9954</span>, <span class="number">0.9950</span>, <span class="number">0.9950</span>, <span class="number">0.9949</span>, <span class="number">0.9947</span>, <span class="number">0.9947</span>, <span class="number">0.9947</span>, <span class="number">0.9947</span>, <span class="number">0.9946</span>,</span><br><span class="line">            <span class="number">0.9946</span>, <span class="number">0.9946</span>, <span class="number">0.9945</span>, <span class="number">0.9945</span>, <span class="number">0.9944</span>])</span><br><span class="line"><span class="built_in">print</span>(idxs)  <span class="comment"># 这个idxs对应的是 pred_scores 那个list的index</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tensor([<span class="number">2511</span>, <span class="number">4528</span>, <span class="number">7139</span>, <span class="number">3953</span>, <span class="number">5800</span>, <span class="number">6515</span>, <span class="number">1615</span>, <span class="number">5915</span>, <span class="number">6805</span>, <span class="number">4924</span>, <span class="number">2905</span>,  <span class="number">548</span>,</span><br><span class="line">            <span class="number">4264</span>, <span class="number">1195</span>, <span class="number">2473</span>, <span class="number">7424</span>, <span class="number">1021</span>, <span class="number">6288</span>, <span class="number">4402</span>, <span class="number">2329</span>, <span class="number">7011</span>, <span class="number">2607</span>, <span class="number">7014</span>, <span class="number">4401</span>,</span><br><span class="line">            <span class="number">6616</span>, <span class="number">6790</span>, <span class="number">7086</span>, <span class="number">5471</span>, <span class="number">1122</span>, <span class="number">2476</span>,  <span class="number">323</span>, <span class="number">3687</span>, <span class="number">3662</span>, <span class="number">6535</span>, <span class="number">2846</span>,  <span class="number">230</span>,</span><br><span class="line">            <span class="number">3932</span>, <span class="number">7364</span>, <span class="number">1606</span>, <span class="number">5276</span>, <span class="number">4092</span>, <span class="number">1289</span>, <span class="number">1551</span>, <span class="number">4703</span>, <span class="number">3322</span>,  <span class="number">747</span>, <span class="number">5077</span>, <span class="number">7031</span>,</span><br><span class="line">            <span class="number">1921</span>, <span class="number">5554</span>])</span><br><span class="line"></span><br><span class="line">topk_idxs = topk_idxs[idxs]</span><br><span class="line"><span class="built_in">print</span>(topk_idxs)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tensor([[<span class="number">72</span>, <span class="number">71</span>],</span><br><span class="line">            [<span class="number">37</span>, <span class="number">67</span>],</span><br><span class="line">            [<span class="number">93</span>, <span class="number">48</span>],</span><br><span class="line">            [<span class="number">77</span>, <span class="number">28</span>],</span><br><span class="line">            [<span class="number">20</span>, <span class="number">72</span>],</span><br><span class="line">            [<span class="number">90</span>, <span class="number">65</span>],</span><br><span class="line">            [<span class="number">99</span>, <span class="number">52</span>],</span><br><span class="line">            [<span class="number">36</span>, <span class="number">45</span>],</span><br><span class="line">            [<span class="number">52</span>, <span class="number">44</span>],</span><br><span class="line">            [<span class="number">68</span>,  <span class="number">7</span>],</span><br><span class="line">            [<span class="number">74</span>, <span class="number">77</span>],</span><br><span class="line">            [<span class="number">76</span>, <span class="number">12</span>],</span><br><span class="line">            [<span class="number">76</span>, <span class="number">49</span>],</span><br><span class="line">            [ <span class="number">5</span>, <span class="number">15</span>],</span><br><span class="line">            [<span class="number">59</span>, <span class="number">14</span>],</span><br><span class="line">            [<span class="number">59</span>, <span class="number">59</span>],</span><br><span class="line">            [<span class="number">40</span>, <span class="number">64</span>],</span><br><span class="line">            [ <span class="number">3</span>, <span class="number">32</span>],</span><br><span class="line">            [<span class="number">29</span>, <span class="number">74</span>],</span><br><span class="line">            [<span class="number">86</span>, <span class="number">66</span>],</span><br><span class="line">            [<span class="number">81</span>, <span class="number">40</span>],</span><br><span class="line">            [<span class="number">18</span>, <span class="number">78</span>],</span><br><span class="line">            [<span class="number">68</span>, <span class="number">25</span>],</span><br><span class="line">            [<span class="number">70</span>, <span class="number">70</span>],</span><br><span class="line">            [<span class="number">47</span>, <span class="number">30</span>],</span><br><span class="line">            [<span class="number">79</span>, <span class="number">61</span>],</span><br><span class="line">            [<span class="number">12</span>,  <span class="number">4</span>],</span><br><span class="line">            [<span class="number">65</span>, <span class="number">23</span>],</span><br><span class="line">            [<span class="number">11</span>, <span class="number">58</span>],</span><br><span class="line">            [<span class="number">21</span>, <span class="number">71</span>],</span><br><span class="line">            [<span class="number">63</span>, <span class="number">68</span>],</span><br><span class="line">            [<span class="number">79</span>, <span class="number">74</span>],</span><br><span class="line">            [<span class="number">19</span>, <span class="number">72</span>],</span><br><span class="line">            [<span class="number">10</span>, <span class="number">52</span>],</span><br><span class="line">            [<span class="number">56</span>, <span class="number">50</span>],</span><br><span class="line">            [<span class="number">91</span>,  <span class="number">1</span>],</span><br><span class="line">            [ <span class="number">1</span>, <span class="number">67</span>],</span><br><span class="line">            [<span class="number">65</span>, <span class="number">35</span>],</span><br><span class="line">            [<span class="number">95</span>, <span class="number">61</span>],</span><br><span class="line">            [<span class="number">52</span>, <span class="number">18</span>],</span><br><span class="line">            [<span class="number">29</span>, <span class="number">50</span>],</span><br><span class="line">            [<span class="number">69</span>, <span class="number">64</span>],</span><br><span class="line">            [<span class="number">96</span>, <span class="number">34</span>],</span><br><span class="line">            [<span class="number">86</span>, <span class="number">41</span>],</span><br><span class="line">            [<span class="number">64</span>, <span class="number">25</span>],</span><br><span class="line">            [<span class="number">43</span>, <span class="number">36</span>],</span><br><span class="line">            [<span class="number">98</span>,  <span class="number">0</span>],</span><br><span class="line">            [<span class="number">23</span>, <span class="number">63</span>],</span><br><span class="line">            [<span class="number">88</span>, <span class="number">30</span>],</span><br><span class="line">            [<span class="number">65</span>, <span class="number">56</span>]])</span><br><span class="line"></span><br><span class="line">anchor_idxs, classes_idxs = topk_idxs.unbind(dim=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 这里得到的是topk的anchor的index以及其对应的class</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后将预测出来的deltas给apply到anchors上</span></span><br><span class="line">pred_boxes = self.box2box_transform.apply_deltas(</span><br><span class="line">    pred_deltas[anchor_idxs], anchors.tensor[anchor_idxs]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回一个Instances的class, 涵盖了一些基本的Meta Info</span></span><br><span class="line"><span class="keyword">return</span> Instances(</span><br><span class="line">    image_size, pred_boxes=Boxes(pred_boxes), scores=pred_scores, pred_classes=classes_idxs</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="Box2BoxTransform">Box2BoxTransform</h4>
<p>使用<code>(dx, dy, dw, dh)</code>对box进行转换, 利用这四个参数将这个box的width和height进行转换: <code>width = exp(dw)</code>, <code>height = exp(dh)</code>, 然后利用<code>(dx, dy)</code>对这个box的center进行转换: <code>center = (dx * width, dy * height)</code>:</p>
<p>这里需要利用<code>detectron2.modeling.box_regression.Box2BoxTransform</code>里提供的功能函数:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_deltas</span>(<span class="params">self, src_boxes, target_boxes</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Get box regression transformation deltas (dx, dy, dw, dh) that can be used</span></span><br><span class="line"><span class="string">    to transform the `src_boxes` into the `target_boxes`. That is, the relation</span></span><br><span class="line"><span class="string">    ``target_boxes == self.apply_deltas(deltas, src_boxes)`` is true (unless</span></span><br><span class="line"><span class="string">    any delta is too large and is clamped).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        src_boxes (Tensor): source boxes, e.g., object proposals</span></span><br><span class="line"><span class="string">        target_boxes (Tensor): target of the transformation, e.g., ground-truth</span></span><br><span class="line"><span class="string">            boxes.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(src_boxes, torch.Tensor), <span class="built_in">type</span>(src_boxes)</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(target_boxes, torch.Tensor), <span class="built_in">type</span>(target_boxes)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算src boxes的宽高以及中心</span></span><br><span class="line">    src_widths = src_boxes[:, <span class="number">2</span>] - src_boxes[:, <span class="number">0</span>]</span><br><span class="line">    src_heights = src_boxes[:, <span class="number">3</span>] - src_boxes[:, <span class="number">1</span>]</span><br><span class="line">    src_ctr_x = src_boxes[:, <span class="number">0</span>] + <span class="number">0.5</span> * src_widths</span><br><span class="line">    src_ctr_y = src_boxes[:, <span class="number">1</span>] + <span class="number">0.5</span> * src_heights</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算target boxes的宽高以及中心</span></span><br><span class="line">    target_widths = target_boxes[:, <span class="number">2</span>] - target_boxes[:, <span class="number">0</span>]</span><br><span class="line">    target_heights = target_boxes[:, <span class="number">3</span>] - target_boxes[:, <span class="number">1</span>]</span><br><span class="line">    target_ctr_x = target_boxes[:, <span class="number">0</span>] + <span class="number">0.5</span> * target_widths</span><br><span class="line">    target_ctr_y = target_boxes[:, <span class="number">1</span>] + <span class="number">0.5</span> * target_heights</span><br><span class="line"></span><br><span class="line">    <span class="comment"># _C.MODEL.RETINANET.BBOX_REG_WEIGHTS = (1.0, 1.0, 1.0, 1.0)</span></span><br><span class="line">    <span class="comment"># 默认用来平衡这几个点的值的weight</span></span><br><span class="line">    wx, wy, ww, wh = self.weights</span><br><span class="line">    dx = wx * (target_ctr_x - src_ctr_x) / src_widths</span><br><span class="line">    dy = wy * (target_ctr_y - src_ctr_y) / src_heights</span><br><span class="line">    dw = ww * torch.log(target_widths / src_widths)</span><br><span class="line">    dh = wh * torch.log(target_heights / src_heights)</span><br><span class="line"></span><br><span class="line">    deltas = torch.stack((dx, dy, dw, dh), dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">assert</span> (src_widths &gt; <span class="number">0</span>).<span class="built_in">all</span>().item(), <span class="string">&quot;Input boxes to Box2BoxTransform are not valid!&quot;</span></span><br><span class="line">    <span class="keyword">return</span> deltas  <span class="comment"># 计算出来deltas</span></span><br></pre></td></tr></table></figure>
<p>利用预测的deltas, 对输入的boxes进行rescale以及shift操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apply_deltas</span>(<span class="params">self, deltas, boxes</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Apply transformation `deltas` (dx, dy, dw, dh) to `boxes`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        deltas (Tensor): transformation deltas of shape (N, k*4), where k &gt;= 1.</span></span><br><span class="line"><span class="string">            deltas[i] represents k potentially different class-specific</span></span><br><span class="line"><span class="string">            box transformations for the single box boxes[i].</span></span><br><span class="line"><span class="string">        boxes (Tensor): boxes to transform, of shape (N, 4)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    deltas = deltas.<span class="built_in">float</span>()  <span class="comment"># ensure fp32 for decoding precision</span></span><br><span class="line">    boxes = boxes.to(deltas.dtype)</span><br><span class="line"></span><br><span class="line">    widths = boxes[:, <span class="number">2</span>] - boxes[:, <span class="number">0</span>]</span><br><span class="line">    heights = boxes[:, <span class="number">3</span>] - boxes[:, <span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 原boxes的centers</span></span><br><span class="line">    ctr_x = boxes[:, <span class="number">0</span>] + <span class="number">0.5</span> * widths</span><br><span class="line">    ctr_y = boxes[:, <span class="number">1</span>] + <span class="number">0.5</span> * heights</span><br><span class="line"></span><br><span class="line">    wx, wy, ww, wh = self.weights</span><br><span class="line">    dx = deltas[:, <span class="number">0</span>::<span class="number">4</span>] / wx</span><br><span class="line">    dy = deltas[:, <span class="number">1</span>::<span class="number">4</span>] / wy</span><br><span class="line">    dw = deltas[:, <span class="number">2</span>::<span class="number">4</span>] / ww</span><br><span class="line">    dh = deltas[:, <span class="number">3</span>::<span class="number">4</span>] / wh</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Prevent sending too large values into torch.exp()</span></span><br><span class="line">    dw = torch.clamp(dw, <span class="built_in">max</span>=self.scale_clamp)</span><br><span class="line">    dh = torch.clamp(dh, <span class="built_in">max</span>=self.scale_clamp)</span><br><span class="line"></span><br><span class="line">    pred_ctr_x = dx * widths[:, <span class="literal">None</span>] + ctr_x[:, <span class="literal">None</span>]</span><br><span class="line">    pred_ctr_y = dy * heights[:, <span class="literal">None</span>] + ctr_y[:, <span class="literal">None</span>]</span><br><span class="line">    pred_w = torch.exp(dw) * widths[:, <span class="literal">None</span>]</span><br><span class="line">    pred_h = torch.exp(dh) * heights[:, <span class="literal">None</span>]</span><br><span class="line"></span><br><span class="line">    x1 = pred_ctr_x - <span class="number">0.5</span> * pred_w</span><br><span class="line">    y1 = pred_ctr_y - <span class="number">0.5</span> * pred_h</span><br><span class="line">    x2 = pred_ctr_x + <span class="number">0.5</span> * pred_w</span><br><span class="line">    y2 = pred_ctr_y + <span class="number">0.5</span> * pred_h</span><br><span class="line">    pred_boxes = torch.stack((x1, y1, x2, y2), dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> pred_boxes.reshape(deltas.shape)</span><br></pre></td></tr></table></figure>
<h4 id="decode-multi-level-predictions">_decode_multi_level_predictions</h4>
<p>主要就是把不同level decode出来的bbox给cat到一起</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_decode_multi_level_predictions</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">    self,</span></span></span><br><span class="line"><span class="params"><span class="function">    anchors: <span class="type">List</span>[Boxes],</span></span></span><br><span class="line"><span class="params"><span class="function">    pred_scores: <span class="type">List</span>[Tensor],</span></span></span><br><span class="line"><span class="params"><span class="function">    pred_deltas: <span class="type">List</span>[Tensor],</span></span></span><br><span class="line"><span class="params"><span class="function">    score_thresh: <span class="built_in">float</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    topk_candidates: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    image_size: <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>],</span></span></span><br><span class="line"><span class="params"><span class="function"></span>) -&gt; Instances:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Run `_decode_per_level_predictions` for all feature levels and concat the results.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    predictions = [</span><br><span class="line">        self._decode_per_level_predictions(</span><br><span class="line">            anchors_i,</span><br><span class="line">            box_cls_i,</span><br><span class="line">            box_reg_i,</span><br><span class="line">            self.test_score_thresh,</span><br><span class="line">            self.test_topk_candidates,</span><br><span class="line">            image_size,</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># Iterate over every feature level</span></span><br><span class="line">        <span class="keyword">for</span> box_cls_i, box_reg_i, anchors_i <span class="keyword">in</span> <span class="built_in">zip</span>(pred_scores, pred_deltas, anchors)</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">return</span> predictions[<span class="number">0</span>].cat(predictions)  <span class="comment"># &#x27;Instances.cat&#x27; is not scriptale but this is</span></span><br></pre></td></tr></table></figure>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Detectron2/" rel="tag"># Detectron2</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/05/25/detectron2-matcher/" rel="prev" title="Detectron2 Learning Notes(5): Matcher">
      <i class="fa fa-chevron-left"></i> Detectron2 Learning Notes(5): Matcher
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/05/26/detectron2-focal-loss/" rel="next" title="Detectron2 Learning Notes(7): Focal Loss">
      Detectron2 Learning Notes(7): Focal Loss <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Contents-2"><span class="nav-number">1.</span> <span class="nav-text">Contents</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DenseDetector"><span class="nav-number">2.</span> <span class="nav-text">DenseDetector</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Forward"><span class="nav-number">2.1.</span> <span class="nav-text">Forward</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#input"><span class="nav-number">2.1.1.</span> <span class="nav-text">input</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#preprocess-image"><span class="nav-number">2.1.2.</span> <span class="nav-text">preprocess_image</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#backbone"><span class="nav-number">2.1.3.</span> <span class="nav-text">backbone</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#predictions"><span class="nav-number">2.1.4.</span> <span class="nav-text">predictions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#forward-training"><span class="nav-number">2.1.5.</span> <span class="nav-text">forward_training</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RetinaNet-Loss-Compute"><span class="nav-number">2.1.6.</span> <span class="nav-text">RetinaNet Loss Compute</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Inference"><span class="nav-number">2.2.</span> <span class="nav-text">Inference</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#decode-single-level-predictions"><span class="nav-number">2.2.1.</span> <span class="nav-text">_decode_single_level_predictions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Box2BoxTransform"><span class="nav-number">2.2.2.</span> <span class="nav-text">Box2BoxTransform</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#decode-multi-level-predictions"><span class="nav-number">2.2.3.</span> <span class="nav-text">_decode_multi_level_predictions</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ren Tianhe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">64</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/rentainhe" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;rentainhe" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/shi-zhi-tou-xi-de-yang-guang" title="ZhiHu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;shi-zhi-tou-xi-de-yang-guang" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i>ZhiHu</a>
      </span>
      <span class="links-of-author-item">
        <a href="/596106517@qq.com" title="E-Mail → 596106517@qq.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ren Tianhe</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">Symbols count total: </span>
    <span title="Symbols count total">258k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">Reading time total &asymp;</span>
    <span title="Reading time total">3:55</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

</body>
</html>
